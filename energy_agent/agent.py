import os, json
from dotenv import load_dotenv
from openai import OpenAI
from duckduckgo_search import ddgs

# è®€å– .env è£¡çš„ API Key
load_dotenv()
client = OpenAI()

# --- å·¥å…·ï¼šæœå°‹ ---
def tool_search(query: str, max_results: int = 3):
    out = []
    with ddgs() as ddgs:
        for r in ddgs.text(query, max_results=max_results):
            title = r.get("title", "")
            href  = r.get("href", "")
            out.append(f"- {title}\n  {href}")
    return "\n".join(out) or "æ²’æœ‰æ‰¾åˆ°è³‡æ–™"

TOOLS = {"search": tool_search}

SYSTEM_PROMPT = """
ä½ æ˜¯ä¸€å€‹ä¸­æ–‡ AI åŠ©ç†ï¼Œå›ç­”å¿…é ˆæ˜¯ä¸­æ–‡ã€‚
ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
- searchï¼šç”¨æ–¼æŸ¥è©¢æœ€æ–°çš„ç¶²è·¯è³‡è¨Šã€‚

ç•¶å•é¡Œéœ€è¦æŸ¥æ‰¾ç¶²è·¯æœ€æ–°è³‡æ–™ã€æ–°èæˆ–äº‹å¯¦æ™‚ï¼Œå¿…é ˆä½¿ç”¨ search å·¥å…·ï¼Œ
æ ¼å¼å¦‚ä¸‹ï¼š
{"tool":"search","args":{"query":"æŸ¥è©¢é—œéµå­—"}}

å¦‚æœå•é¡Œæ˜¯ä¸€èˆ¬çŸ¥è­˜æˆ–æ•¸å­¸é‹ç®—ï¼Œæ‰å¯ç›´æ¥å›ç­”ï¼š
{"final_answer":"ä½ çš„ä¸­æ–‡å›ç­”"}
"""

def ask_llm(user_input: str) -> str:
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_input},
        ],
        temperature=0.3,
    )
    return resp.choices[0].message.content.strip()

def run_once(user_input: str) -> str:
    raw = ask_llm(user_input)
    try:
        js = json.loads(raw)
    except:
        return raw

    if "final_answer" in js:
        return js["final_answer"]

    tool = js.get("tool")
    if tool in TOOLS:
        result = TOOLS[tool](**js.get("args", {}))
        return ask_llm(f"å·¥å…·çµæœå¦‚ä¸‹ï¼š\n{result}\nè«‹çµ¦å‡ºæœ€çµ‚å›ç­”ã€‚")
    else:
        return "æœªçŸ¥çš„å·¥å…·æˆ–æ ¼å¼éŒ¯èª¤ã€‚"

if __name__ == "__main__":
    print("ğŸ§  AI Agent å•Ÿå‹•ï¼ˆè¼¸å…¥ exit é›¢é–‹ï¼‰")
    while True:
        q = input("\nä½ ï¼š").strip()
        if q.lower() in {"exit", "quit"}:
            break
        print("Agentï¼š", run_once(q))
